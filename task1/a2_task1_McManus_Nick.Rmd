---
title: "Task 1: Palmetto Binary Logistic Regression"
author: "Nick McManus"
date: "2023-02-12"
output: 
 html_document: 
    toc: yes
    toc_float: yes
    theme: cerulean
    code_folding: hide
    smooth_scroll: yes
    collapsed: yes
---

```{r setup, include=TRUE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)  #always
library(broom)      #tidy tables
library(GGally)     #plotting 
library(AICcmodavg) #compare AIC values
library(tidymodels) #k-fold cross validation
library(kableExtra) #tables
library(cowplot)    #figures
```

# Introduction
***

In this task, we create and compare two different binary logistic regression models for predicting palmetto species in south-central Florida. These models are created and tested using a long-term dataset of the two dominant palmetto species at the Archbold Biological Station: *Serenoa repens* and *Sabel etonia*. These data were collected at five-year intervals between 1981-2017.

To understand how well measured variables -- such as plant height, canopy length and width, and number of new green leaves -- can classify palmetto species, we'll first visualize the relationship between species and predictor variables. Then, metrics such as AICc, BIC, and cross validation are used to determine which of two models best predicts the palmetto species. 

**Source:** Abrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5

<br><br>

# Visual exploration
***

```{r}
## read in the data

palmetto <- read_csv("palmetto.csv") %>% 
  # keep variables of interest
  select(species, height:green_lvs) %>% 
  # change number to species name
  mutate(species = case_when(species == 1 ~ 'S. repens',
                             species == 2 ~ 'S. etonia'),
         species = factor(species)) %>% 
  # drop any NAs
  drop_na()

# Quickly visualize variable relationships
#ggpairs(data = palmetto, aes(color = species))
```


```{r}
### visualize differences in height and canopy length

## create overlapping plot
height_length_overlap <- ggplot(data = palmetto, aes(x = height, y = length)) +
  geom_point(aes(color = species)) +
  labs(x = 'Height (cm)',
       y = 'Canopy length (cm)') +
  scale_color_manual(values = c('seagreen4', 'seagreen2'))+
  theme_bw() +
  theme(
    #customize legend elements
    legend.position = c(0.12, 0.8),
    legend.title = element_text(face = 'bold', size = 9),
    legend.text = element_text(face = 'italic', size = 9),
    legend.background = element_rect(fill = 'honeydew'),
    legend.key = element_rect(fill = 'honeydew'),
    legend.key.size = unit(1, 'line'),
    legend.box.background = element_rect(color = 'black'),
    #customize axis elements
    axis.text.x = element_text(size = 8),
    axis.text.y = element_text(size = 8),
    axis.title.x = element_text(size = 10, face = 'bold'),
    axis.title.y = element_text(size = 10, face = 'bold'),
    panel.background = element_rect(fill = 'azure')) +
  #change legend dot size and title
  guides(colour = guide_legend(override.aes = list(size = 3), title = "Species:"))


## create facet wrapped plot
height_length_sep <- ggplot(data = palmetto, aes(x = height, y = length)) +
  geom_point(aes(color = species), alpha = 0.8, show.legend = FALSE) +
  labs(x = 'Height (cm)',
       y = 'Canopy length (cm)') +
  facet_wrap(~species) +
  scale_color_manual(values = c('seagreen4', 'seagreen2'))+
  theme_bw()+
  theme(
    axis.text.x = element_text(size = 8),
    axis.text.y = element_text(size = 8),
    axis.title.x = element_text(size = 10, face = 'bold'),
    axis.title.y = element_text(size = 10, face = 'bold'),
    panel.background = element_rect(fill = 'azure'))
```

```{r, fig.height = 8, fig.width = 7}
## plot both graphs together
plot_grid(height_length_overlap, height_length_sep,
          align = 'V',
          ncol = 1,
          labels = c('A', 'B'),
          hjust = -1,
          vjust = 1.8)
```

**Fig 1.** Height (cm) and canopy length (cm) of Palmetto species measured at the Archbold Biological Station from 1981-2017. Observations for *S. etonia* and *S. repens* are displayed in dark and light green, respectively. Fig 1A (top) directly compares observations for both species, while 1B (bottom) separates observations to better visualize the spread of each species. 

<br><br>

```{r}
#quantify the difference
leaf_stats <- palmetto %>% 
  group_by(species) %>% 
  summarize(mean_lvs = mean(green_lvs),
            sd_lvs = sd(green_lvs))


# histogram of green leaves by species
ggplot(data = palmetto, aes(x = green_lvs)) +
  #boxes for s.etonia
  geom_histogram(data = subset(palmetto, species == 'S. etonia'), 
                 aes(fill = species),
                 binwidth = 1, 
                 boundary = -0.5, #adjust axis for better labeling
                 color = 'black', 
                 alpha = 0.85) +
  #boxes for s.repens
  geom_histogram(data = subset(palmetto, species == 'S. repens'), 
                 aes(fill = species),
                 binwidth = 1, boundary = -0.5,
                 color = 'gray20',
                 alpha = 0.6) +
  #set colors and legend values
  scale_fill_manual(name = 'Species', 
                    values = c('seagreen4', 'seagreen2'),
                    labels = c('S. etonia', 'S. repens')) +
  #force origin to (0,0) and x-axis labels through 17
  scale_x_continuous(expand = c(0, 0), limits = c(0, 18), breaks=1:17) + 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 2100)) +
  #axis labels
  labs(x = 'Number of green leaves',
       y = 'Count') +
  #set theme
  theme_classic() +
  theme(
    axis.title.x = element_text(face = 'bold', vjust = -0.5),
    axis.title.y = element_text(face = 'bold'),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(vjust = 2),
    legend.position = c(0.8, 0.8),
    legend.title = element_text(face = 'bold', size = 10),
    legend.text = element_text(face = 'italic'),
    legend.key.size = unit(1, 'line'))
```

**Fig 2.** The number of green leaves on a palmetto for two species measured at the Archbold Biological Station. Observations for *S. etonia* and *S. repens* are displayed in dark and light green, respectively. On average, *S. etonia* have `r round(leaf_stats$mean_lvs[1],1)`<font size="1">$\pm$</font>`r round(leaf_stats$sd_lvs[1],1)` green leaves while *S. repens* have `r round(leaf_stats$mean_lvs[2],1)`<font size="1">$\pm$</font>`r round(leaf_stats$sd_lvs[2],1)` green leaves (mean <font size="1">$\pm$</font> 1 standard deviation). The histograms' difference in spread and central location reflect *S. repens* greater variability and average number of green leaves per plant.  

<br>

Based on Figures 1 and 2, the number of green leaves noticeably differs between species, while height and canopy length narrowly differ; as such, height and canopy length may not serve as useful predictor variables in determining palmetto species. Figure 1 does show that canopy length is slightly greater for *S. etonia* plants with the same height as *S. repens*; however, to determine how much length helps classify species, we'll create and compare two models and perform a binary logistic regression. 

<br>

# Binary Logistic Regression
***

## Compare Models
Our first model will classify palmetto species by plant height, canopy length and width, and the number of green leaves. Our second model will eschew canopy length, and we'll evaluate if the increased simplicity results in a better model. This begins with evaluating the log odds of plant type based on the predictor variables in each model. 
```{r}
# first formula considers all variables
f1 <- species ~ height + width + length + green_lvs
blr1 <- glm(formula = f1, data = palmetto, family = "binomial")

# second formula excludes canopy length
f2 <- species ~ height + width + green_lvs
blr2 <- glm(f2, palmetto, family = "binomial")

# Get a tidy version w/ broom
blr1_tidy <- tidy(blr1)
blr2_tidy <- tidy(blr2)

# return tables with log odds
blr1_tidy %>% 
  kable(caption = "**Table 1.** BLR results for Model 1.",
        col.names = c("Variable", "Coefficient", "Standard error", "Statistic", "p-value")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")
blr2_tidy %>% 
  kable(caption = "**Table 2.** BLR results for Model 2.",
        col.names = c("Variable", "Coefficient", "Standard error", "Statistic", "p-value")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")

```


The coefficients for each predictor variable in log-linear Models 1 and 2 are displayed in Tables 1 and 2, respectively. In both models, the number of green leaves has the largest coefficient. In Model 1, for example, a coefficient of `r round(blr1_tidy$estimate[5],4)` indicates that, on average, the log odds of a palmetto being *S. repens* increases by `r round(blr1_tidy$estimate[5],4)` for each additional green leaf present. The canopy length has the second highest coefficient value, `r round(blr1_tidy$estimate[4],4)`, in Model 1; this indicates that removing canopy length from Model 2 may result in a less accurate predictor of palmetto species. To help determine if this is true, we'll compare the corrected Akaike information criterion (AICc) and Bayesian information criterion (BIC) values, as well as perform a cross validation, for both models.  

```{r}
### AICc ------------------------------------------------------------
aic <- aictab(list(blr1, blr2)) 
## make nice AICc table
aic_table <- aic %>% 
  kable(caption = "**Table 3.** AICc values for Models 1 and 2.",
        col.names = c("Model", "Parameters", "AICc", 
                      "Delta AICc", "mdlLik","aiccwt", 
                      "Log Likelihood", "cum.wt")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left") %>% 
  remove_column(c(5,6,8)) #remove unnecessary columns

### BIC  ------------------------------------------------------------
bic <- bictab(list(blr1, blr2))
## make nice BIC table
bic_table <- bic %>% 
  kable(caption = "**Table 4.** BIC values for Models 1 and 2.",
        col.names = c("Model", "Parameters", "AICc", 
                      "Delta AICc", "mdlLik","aiccwt", 
                      "Log Likelihood", "cum.wt")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left") %>% 
  remove_column(c(5,6,8)) #remove unnecessary columns


## call tables
aic_table
bic_table
```

As shown in Table 3, Model 1 has an AICc value of `r round(aic$AICc[1],2)`, while Model 2 has an AICc of `r round(aic$AICc[2],2)`. This difference of `r round(aic$Delta_AICc[2],2)` indicates that Model 1 predicts palmetto species significantly better than Model 2. The BIC values for the two models differ by `r round(bic$Delta_BIC[2],2)`, further supporting that Model 1 is the better choice.  

<br>

Using the {tidymodels} package, we'll run a repeated cross validation (10-fold repeated 10 times) for both models: 
```{r}
### set the stage ------------------------------------------------------
## set seed for reproducibility 
set.seed(123)

## set number of folds to 10 and repeat it 5 times
n_folds <- vfold_cv(palmetto, v = 10, repeats = 10)

## create general BLR model
blr_model <- logistic_reg() %>% 
  set_engine('glm')



### set up workflow bundling logistic model with formula ---------------
## Run for formula 1
blr_tidy_wf1 <- workflow() %>%
  add_model(blr_model) %>%
  add_formula(f1)

blr_tidy_cv_f1 <- blr_tidy_wf1 %>%
  fit_resamples(n_folds)

# output useful metrics
cv_metrics_f1 <- collect_metrics(blr_tidy_cv_f1)


## Run for formula 2
blr_tidy_wf2 <- workflow() %>%
  add_model(blr_model) %>%
  add_formula(f2)

blr_tidy_cv_f2 <- blr_tidy_wf2 %>%
  fit_resamples(n_folds)

# output useful metrics
cv_metrics_f2 <- collect_metrics(blr_tidy_cv_f2) 
 

### create tables for cv metrics ---------------------------------------
## model 1
cv_metrics_f1 %>% 
  kable(caption = '**Table 5.** Cross validation metrics for Model 1.',
        col.names = c('Metric', 'Estimator', 'Mean',
                      'n', 'Standard error', 'Configuration')) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")
## model 2
cv_metrics_f2 %>% 
  kable(caption = '**Table 6.** Cross validation metrics for Model 2.',
        col.names = c('Metric', 'Estimator', 'Mean',
                      'n', 'Standard error', 'Configuration')) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")

```

As displayed in Tables 5 and 6, the mean accuracy of Model 1 is `r round(cv_metrics_f1$mean[1],4)`, while the mean accuracy for Model 2 is `r round(cv_metrics_f2$mean[1],4)`. Based on these cross validation results, as well as the AICc and BIC values, Model 1 performs better at species classification. 

<br>

# Model Correctness
***

Now that we've selected Model 1, we'll train it with the entire palmetto dataset and return it's coefficients.
```{r}
# use the entire dataset to train model
blr1_tidyfit <- blr_model %>% 
  fit(f1, data = palmetto)

# output coefficients in nice table
coeffs_blr1_tidy <- tidy(blr1_tidyfit)
coeffs_blr1_tidy %>% 
  kable(caption = "**Table 7.** BLR coefficients for final model.",
        col.names = c("Variable", "Coefficient", "Standard error", "Statistic", "p-value")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")
```


Because the log-odds are difficult to interpret, we'll convert them to the probabilities and then evaluate how successfully the model actually classifies a given plant as the correct species. This will be done using a 50% cutoff.

```{r}
# convert log odds to probabilities with type.predict 
blr1_fitted <- blr1 %>%
  broom::augment(type.predict = 'response')

# function to calculate percent accuracy
pred_acc <- function(x, y) {
  accurate <- ifelse(x == y, 1, 0)
  return(mean(accurate, na.rm = TRUE)*100)
}

# check the accuracy of the model by species
blr1_accuracy <- blr1_fitted %>% 
  #predict species based on 50% threshold
  mutate(species_pred = ifelse(.fitted > 0.5, 'S. repens', 'S. etonia')) %>% 
  #return 1 if prediction was correct, 0 if not
  mutate(correct_pred = ifelse(species_pred == species, 'yes', 'no')) %>% 
  #summary stats for both species, how many correct preds (and percentage)
  group_by(species) %>% 
  summarize(n_correct = sum(correct_pred == 'yes'),
            n_incorrect = sum(correct_pred == 'no'),
            pct_correct = round(pred_acc(species, species_pred),3))
  
# output nice table
blr1_accuracy %>% 
  kable(caption = "**Table 8.** Classification accuracy for final model.",
        col.names = c("Species", 
                      "Correctly classified (n)", 
                      "Incorrectly classified (n)", 
                      "Percent correctly classified (%)")) %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = "hover",
                position = "left")
  
```

By using plant height, canopy length and width, and number of green leaves as predictor variables, Model 1 served as a better predictor of palmetto species than Model 2. This decision was supported by the AICc values, BIC values, and results from a cross validation for both models. Table 8 illustrates that Model 1 correctly classifies palmettos as either *S. repens* or *S. etonia* `r round((blr1_accuracy[1,4] + blr1_accuracy[2,4])/2, 2)`% of the time, on average. 

